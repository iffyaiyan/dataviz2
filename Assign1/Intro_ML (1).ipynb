{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7gPVndapoTT"
      },
      "outputs": [],
      "source": [
        "## Code to convert mpg to mp4 form\n",
        "\n",
        "from IPython.display import Video\n",
        "\n",
        "video_path = \"/content/umcp.mpg\"\n",
        "Video(video_path, embed=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part 1: Video Summarisation**"
      ],
      "metadata": {
        "id": "XCJXQ6PDc0bM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "## For Video summarisation few steps needs to be done as mentioend below\n",
        "\n",
        "## 1. extract_frames\n",
        "## 2. preprocess_frames\n",
        "## 3. compute_motion\n",
        "## 4. apply_pca\n",
        "## 5. select_key_frames\n",
        "## 6. segment_and_summarize\n",
        "\n",
        "# Step 1: Extract frames from the video\n",
        "def extract_frames(video_path, frame_interval=1):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    frames = []\n",
        "    frame_count = 0\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        if frame_count % frame_interval == 0:\n",
        "            frames.append(frame)\n",
        "        frame_count += 1\n",
        "    cap.release()\n",
        "    return frames\n",
        "\n",
        "# Step 2: Preprocess frames (to resize and convert to grayscale)\n",
        "def preprocess_frames(frames, size=(128, 128)):\n",
        "    processed_frames = []\n",
        "    for frame in frames:\n",
        "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        resized = cv2.resize(gray, size)\n",
        "        processed_frames.append(resized)\n",
        "    return processed_frames\n",
        "\n",
        "# Step 3: Compute motion between consecutive frames\n",
        "def compute_motion(frames):\n",
        "    motion = []\n",
        "    for i in range(1, len(frames)):\n",
        "        diff = cv2.absdiff(frames[i], frames[i-1])\n",
        "        motion.append(diff)\n",
        "    return motion\n",
        "\n",
        "# Step 4: Apply PCA to identify key frames\n",
        "def apply_pca(input_motion, n_components=10):\n",
        "    motion_array = np.array(input_motion).reshape(len(input_motion), -1)\n",
        "    pca = PCA(n_components=n_components)\n",
        "    pca.fit(motion_array)\n",
        "    return pca\n",
        "\n",
        "# Step 5: Select key frames based on PCA\n",
        "def select_key_frames(frames, pca, n_key_frames=10):\n",
        "    motion_array = np.array(frames).reshape(len(frames), -1)\n",
        "    transformed = pca.transform(motion_array)\n",
        "    key_frame_indices = np.argsort(-transformed.sum(axis=1))[:n_key_frames]\n",
        "    key_frames = [frames[i] for i in key_frame_indices]\n",
        "    return key_frames\n",
        "\n",
        "# Step 6: Summarize the video by stitching key frames\n",
        "def summarize_video(key_frames, output_path=\"summarized_video.mp4\"):\n",
        "    height, width = key_frames[0].shape\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')   # FourCC is a 4-byte code used to specify the video codec\n",
        "    out = cv2.VideoWriter(output_path, fourcc, 1, (width, height), isColor=False)\n",
        "    for frame in key_frames:\n",
        "        out.write(frame)\n",
        "    out.release()\n",
        "\n",
        "# Step 7: Segment the video and extract key frames from each segment\n",
        "def segment_and_summarize(video_path, n_segments=10, n_key_frames_per_segment=2):\n",
        "    # Step 1: Extract frames\n",
        "    frames = extract_frames(video_path)\n",
        "\n",
        "    # Step 2: Preprocess frames\n",
        "    processed_frames = preprocess_frames(frames)\n",
        "\n",
        "    # Step 3: Divide frames into segments\n",
        "    segment_size = len(processed_frames) // n_segments\n",
        "    all_key_frames = []\n",
        "\n",
        "    for i in range(n_segments):\n",
        "        start = i * segment_size\n",
        "        end = (i + 1) * segment_size if i < n_segments - 1 else len(processed_frames)\n",
        "        segment_frames = processed_frames[start:end]\n",
        "\n",
        "        # Step 4: Compute motion for the segment\n",
        "        motion = compute_motion(segment_frames)\n",
        "\n",
        "        # Step 5: Apply PCA to the segment\n",
        "        pca = apply_pca(motion)\n",
        "\n",
        "        ## to check variance\n",
        "        # explained_variance = np.cumsum(pca.explained_variance_ratio_)\n",
        "        # plt.plot(explained_variance)\n",
        "        # plt.xlabel('Number of Components')\n",
        "        # plt.ylabel('Cumulative Explained Variance')\n",
        "        # plt.show()\n",
        "\n",
        "\n",
        "        # Step 6: Select key frames for the segment\n",
        "        key_frames = select_key_frames(segment_frames, pca, n_key_frames=n_key_frames_per_segment)\n",
        "        all_key_frames.extend(key_frames)\n",
        "\n",
        "    # Step 7: Summarize video using all key frames\n",
        "    summarize_video(all_key_frames)\n",
        "    print(f\"Summarized video is saved as 'summarized_video.mp4' with {len(all_key_frames)} key frames.\")\n",
        "\n",
        "# Run the code\n",
        "video_path = \"/content/video.mp4\"\n",
        "segment_and_summarize(video_path, n_segments=10, n_key_frames_per_segment=2)\n",
        "\n",
        "## Experimentation with different number of frames\n",
        "# segment_and_summarize(video_path, n_segments=10, n_key_frames_per_segment=3)\n",
        "# segment_and_summarize(video_path, n_segments=10, n_key_frames_per_segment=5)\n",
        "# segment_and_summarize(video_path, n_segments=10, n_key_frames_per_segment=7)\n",
        "# segment_and_summarize(video_path, n_segments=10, n_key_frames_per_segment=9)"
      ],
      "metadata": {
        "id": "91rNFCdtqQ3U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e52c115-1611-4ed6-ab14-480d94134a89"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized video is saved as 'summarized_video.mp4' with 20 key frames.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Below is the implementation of the PCA from scratch**"
      ],
      "metadata": {
        "id": "pS6IdM9RiZ-G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's Implement PCA from Scratch\n",
        "class LocalPCA:\n",
        "    def __init__(self, n_components):\n",
        "        self.n_components = n_components\n",
        "        self.mean = None\n",
        "        self.components = None\n",
        "\n",
        "    ## fit function\n",
        "    def fit(self, X):\n",
        "        # Step 1: We first need to center the data\n",
        "        self.mean = np.mean(X, axis=0)\n",
        "        X_centered = X - self.mean\n",
        "\n",
        "        # Step 2: Then we need to compute covariance matrix\n",
        "        covariance_matrix = np.cov(X_centered, rowvar=False)\n",
        "\n",
        "        # Step 3: We need to compute eigenvalues and eigenvectors\n",
        "        eigenvalues, eigenvectors = np.linalg.eig(covariance_matrix)\n",
        "\n",
        "        # Step 4: After that we will have to sort eigenvectors by eigenvalues in descending order\n",
        "        sorted_indices = np.argsort(-eigenvalues)\n",
        "        self.components = eigenvectors[:, sorted_indices[:self.n_components]]\n",
        "\n",
        "    ## transform function\n",
        "    def transform(self, X):\n",
        "        X_centered = X - self.mean\n",
        "        return np.dot(X_centered, self.components)\n",
        "\n",
        "    ## fit transform function\n",
        "    def fit_transform(self, X):\n",
        "        self.fit(X)\n",
        "        return self.transform(X)\n"
      ],
      "metadata": {
        "id": "62zj-lDlgCy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Please uncomment the code to run the PCALocal implementation\n",
        "\n",
        "\n",
        "# import cv2\n",
        "# import numpy as np\n",
        "# from sklearn.decomposition import PCA\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# # Step 1: Extract frames from the video\n",
        "# def extract_frames(video_path, frame_interval=1):\n",
        "#     cap = cv2.VideoCapture(video_path)\n",
        "#     frames = []\n",
        "#     frame_count = 0\n",
        "#     while True:\n",
        "#         ret, frame = cap.read()\n",
        "#         if not ret:\n",
        "#             break\n",
        "#         if frame_count % frame_interval == 0:\n",
        "#             frames.append(frame)\n",
        "#         frame_count += 1\n",
        "#     cap.release()\n",
        "#     return frames\n",
        "\n",
        "# # Step 2: Preprocess frames (resize and convert to grayscale)\n",
        "# def preprocess_frames(frames, size=(128, 128)):\n",
        "#     processed_frames = []\n",
        "#     for frame in frames:\n",
        "#         gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "#         resized = cv2.resize(gray, size)\n",
        "#         processed_frames.append(resized)\n",
        "#     return processed_frames\n",
        "\n",
        "# # Step 3: Compute motion between consecutive frames\n",
        "# def compute_motion(frames):\n",
        "#     motion = []\n",
        "#     for i in range(1, len(frames)):\n",
        "#         diff = cv2.absdiff(frames[i], frames[i-1])\n",
        "#         motion.append(diff)\n",
        "#     return motion\n",
        "\n",
        "# # Step 4: Apply PCA to identify key frames\n",
        "# # def apply_pca(motion, n_components=10):\n",
        "# #     motion_array = np.array(motion).reshape(len(motion), -1)\n",
        "# #     pca = PCA(n_components=n_components)\n",
        "# #     pca.fit(motion_array)\n",
        "# #     return pca\n",
        "\n",
        "# def apply_pca_scratch(motion, n_components=10):\n",
        "#     motion_array = np.array(motion).reshape(len(motion), -1)\n",
        "#     pca = LocalPCA(n_components=n_components)\n",
        "#     transformed_data = pca.fit_transform(motion_array)\n",
        "#     return pca, transformed_data\n",
        "\n",
        "# # Step 5: Select key frames based on PCA\n",
        "# def select_key_frames(frames, pca, n_key_frames=10):\n",
        "#     motion_array = np.array(frames).reshape(len(frames), -1)\n",
        "#     transformed = pca.transform(motion_array)\n",
        "#     key_frame_indices = np.argsort(-transformed.sum(axis=1))[:n_key_frames]\n",
        "#     key_frames = [frames[i] for i in key_frame_indices]\n",
        "#     return key_frames\n",
        "\n",
        "# # Step 6: Summarize the video by stitching key frames\n",
        "# def summarize_video(key_frames, output_path=\"summarized_video.mp4\"):\n",
        "#     height, width = key_frames[0].shape\n",
        "#     fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "#     out = cv2.VideoWriter(output_path, fourcc, 1, (width, height), isColor=False)\n",
        "#     for frame in key_frames:\n",
        "#         out.write(frame)\n",
        "#     out.release()\n",
        "\n",
        "# # Step 7: Segment the video and extract key frames from each segment\n",
        "# def segment_and_summarize(video_path, n_segments=10, n_key_frames_per_segment=2):\n",
        "#     # Step 1: Extract frames\n",
        "#     frames = extract_frames(video_path)\n",
        "\n",
        "#     # Step 2: Preprocess frames\n",
        "#     processed_frames = preprocess_frames(frames)\n",
        "\n",
        "#     # Step 3: Divide frames into segments\n",
        "#     segment_size = len(processed_frames) // n_segments\n",
        "#     all_key_frames = []\n",
        "\n",
        "#     for i in range(n_segments):\n",
        "#         start = i * segment_size\n",
        "#         end = (i + 1) * segment_size if i < n_segments - 1 else len(processed_frames)\n",
        "#         segment_frames = processed_frames[start:end]\n",
        "\n",
        "#         # Step 4: Compute motion for the segment\n",
        "#         motion = compute_motion(segment_frames)\n",
        "\n",
        "#         # Step 5: Apply PCA to the segment\n",
        "#         pca = apply_pca_scratch(motion)\n",
        "\n",
        "#         # Step 6: Select key frames for the segment\n",
        "#         key_frames = select_key_frames(segment_frames, pca, n_key_frames=n_key_frames_per_segment)\n",
        "#         all_key_frames.extend(key_frames)\n",
        "\n",
        "#     # Step 7: Summarize video using all key frames\n",
        "#     summarize_video(all_key_frames)\n",
        "#     print(f\"Summarized video saved as 'summarized_video.mp4' with {len(all_key_frames)} key frames.\")\n",
        "\n",
        "# # Run the code\n",
        "# video_path = \"/content/video.mp4\"  # Replace with your video path\n",
        "# segment_and_summarize(video_path, n_segments=10, n_key_frames_per_segment=2)"
      ],
      "metadata": {
        "id": "qT1tVMoHgFD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Part2**"
      ],
      "metadata": {
        "id": "gDPTzOWnzmuG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "## Defining GaussianMixture\n",
        "class GaussianMixture:\n",
        "    def __init__(self, n_components=3, learning_rate=0.01, threshold=0.7, var_threshold=16):   ## All the default parameters here can be tuned, but in my case these are working optimum\n",
        "        self.n_components = n_components\n",
        "        self.learning_rate = learning_rate\n",
        "        self.threshold = threshold\n",
        "        self.var_threshold = var_threshold\n",
        "        self.weights = None\n",
        "        self.means = None\n",
        "        self.covars = None\n",
        "        self.initialized = False\n",
        "\n",
        "    def initialize(self, first_frame):\n",
        "        height, width = first_frame.shape[:2]\n",
        "        self.weights = np.ones((height, width, self.n_components)) / self.n_components\n",
        "        self.means = np.zeros((height, width, self.n_components))\n",
        "        self.covars = np.ones((height, width, self.n_components)) * self.var_threshold\n",
        "        self.means[:,:,0] = first_frame\n",
        "        self.initialized = True\n",
        "\n",
        "    def gaussian_prob(self, x, mean, covar):\n",
        "        diff = x - mean\n",
        "        return np.exp(-diff * diff / (2 * covar)) / np.sqrt(2 * np.pi * covar)\n",
        "\n",
        "    def update(self, frame):\n",
        "        if not self.initialized:\n",
        "            self.initialize(frame)\n",
        "            return np.ones_like(frame, dtype=bool)\n",
        "\n",
        "        height, width = frame.shape[:2]\n",
        "        matches = np.zeros((height, width, self.n_components), dtype=bool)\n",
        "\n",
        "        # Calculating match for each component\n",
        "        for i in range(self.n_components):\n",
        "            diff = np.abs(frame - self.means[:,:,i])\n",
        "            matches[:,:,i] = diff < 2.5 * np.sqrt(self.covars[:,:,i])\n",
        "\n",
        "        # Update parameters for matched components\n",
        "        for i in range(self.n_components):\n",
        "            match_pixels = matches[:,:,i]\n",
        "\n",
        "            if np.any(match_pixels):\n",
        "                # Update weights\n",
        "                self.weights[:,:,i] = (1 - self.learning_rate) * self.weights[:,:,i]\n",
        "                self.weights[match_pixels,i] += self.learning_rate\n",
        "\n",
        "                # Update means and variances for matched pixels\n",
        "                pixel_diff = frame[match_pixels] - self.means[match_pixels,i]\n",
        "                self.means[match_pixels,i] += self.learning_rate * pixel_diff\n",
        "                self.covars[match_pixels,i] += self.learning_rate * (\n",
        "                    pixel_diff * pixel_diff - self.covars[match_pixels,i]\n",
        "                )\n",
        "\n",
        "        # Normalize weights\n",
        "        weight_sum = np.sum(self.weights, axis=2)\n",
        "        np.divide(self.weights, weight_sum[:,:,np.newaxis], out=self.weights)\n",
        "\n",
        "        # Determine foreground pixels\n",
        "        sorted_indices = np.argsort(self.weights, axis=2)\n",
        "        sorted_weights = np.take_along_axis(self.weights, sorted_indices, axis=2)\n",
        "        cumsum = np.cumsum(sorted_weights, axis=2)\n",
        "        threshold_mask = cumsum < self.threshold\n",
        "\n",
        "        background_prob = np.zeros((height, width))\n",
        "        for i in range(self.n_components):\n",
        "            background_prob += self.weights[:,:,i] * self.gaussian_prob(\n",
        "                frame, self.means[:,:,i], self.covars[:,:,i]\n",
        "            )\n",
        "\n",
        "        return background_prob < 0.1\n",
        "\n",
        "class BackgroundSubtractor:\n",
        "    def __init__(self, video_path, output_dir=\"output\"):\n",
        "        self.video_path = video_path\n",
        "        self.output_dir = output_dir\n",
        "        self.gmm = GaussianMixture()\n",
        "        self.setup_output_directories()\n",
        "\n",
        "    def setup_output_directories(self):\n",
        "        if not os.path.exists(self.output_dir):\n",
        "            os.makedirs(self.output_dir)\n",
        "\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        self.frames_dir = os.path.join(self.output_dir, f\"frames_{timestamp}\")\n",
        "        self.bg_dir = os.path.join(self.output_dir, f\"background_{timestamp}\")\n",
        "        self.fg_dir = os.path.join(self.output_dir, f\"foreground_{timestamp}\")\n",
        "\n",
        "        for directory in [self.frames_dir, self.bg_dir, self.fg_dir]:\n",
        "            if not os.path.exists(directory):\n",
        "                os.makedirs(directory)\n",
        "\n",
        "    def final_video_processor(self):\n",
        "        cap = cv2.VideoCapture(self.video_path)\n",
        "        if not cap.isOpened():\n",
        "            raise ValueError(\"Error opening video file\")\n",
        "\n",
        "        frame_count = 0\n",
        "\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            # Convert to grayscale\n",
        "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "            # Get foreground mask\n",
        "            foreground_mask = self.gmm.update(gray)\n",
        "\n",
        "            # Save frames\n",
        "            cv2.imwrite(f\"{self.frames_dir}/frame_{frame_count:04d}.jpg\", frame)\n",
        "\n",
        "            # Create and save background/foreground\n",
        "            background = frame.copy()\n",
        "            foreground = frame.copy()\n",
        "\n",
        "            background[foreground_mask] = 0\n",
        "            foreground[~foreground_mask] = 0\n",
        "\n",
        "            cv2.imwrite(f\"{self.bg_dir}/bg_{frame_count:04d}.jpg\", background)\n",
        "            cv2.imwrite(f\"{self.fg_dir}/fg_{frame_count:04d}.jpg\", foreground)\n",
        "\n",
        "            frame_count += 1\n",
        "\n",
        "        cap.release()\n",
        "        self.generate_videos()\n",
        "        self.save_parameters()\n",
        "\n",
        "    def generate_videos(self):\n",
        "        def images_to_video(image_folder, output_path, fps=30):\n",
        "            images = [img for img in os.listdir(image_folder) if img.endswith(\".jpg\")]\n",
        "            images.sort()\n",
        "\n",
        "            if not images:\n",
        "                return\n",
        "\n",
        "            frame = cv2.imread(os.path.join(image_folder, images[0]))\n",
        "            height, width = frame.shape[:2]\n",
        "\n",
        "            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "            out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "            for image in images:\n",
        "                frame = cv2.imread(os.path.join(image_folder, image))\n",
        "                out.write(frame)\n",
        "\n",
        "            out.release()\n",
        "\n",
        "        images_to_video(self.bg_dir, os.path.join(self.output_dir, \"background.mp4\"))\n",
        "        images_to_video(self.fg_dir, os.path.join(self.output_dir, \"foreground.mp4\"))\n",
        "\n",
        "    def save_parameters(self):\n",
        "        params = f\"\"\"Background Subtraction Parameters\n",
        "========================\n",
        "Timestamp: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}\n",
        "\n",
        "GMM Parameters:\n",
        "-------------\n",
        "Number of components: {self.gmm.n_components}\n",
        "Learning rate: {self.gmm.learning_rate}\n",
        "Background threshold: {self.gmm.threshold}\n",
        "Variance threshold: {self.gmm.var_threshold}\n",
        "\n",
        "Processing Details:\n",
        "-----------------\n",
        "Input video: {self.video_path}\n",
        "Output directory: {self.output_dir}\n",
        "\n",
        "Additional Information:\n",
        "--------------------\n",
        "- Implementation uses Gaussian Mixture Model (GMM) from scratch\n",
        "- Background is modeled using {self.gmm.n_components} Gaussian components\n",
        "- Pixels are classified as foreground when their probability is below threshold\n",
        "- Sequential frame processing with online parameter updates\n",
        "\"\"\"\n",
        "\n",
        "        with open(os.path.join(self.output_dir, \"parameters.txt\"), \"w\") as f:\n",
        "            f.write(params)\n",
        "\n",
        "# Create a background subtractor instance\n",
        "subtractor = BackgroundSubtractor(\"/content/video.mp4\")\n",
        "\n",
        "# Process the video\n",
        "subtractor.final_video_processor()"
      ],
      "metadata": {
        "id": "K2zHf560gU1G"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1T9wi1PFDvQ",
        "outputId": "f719398d-b93b-4f2f-96b3-04525355b4e7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:pydrive is deprecated and no longer maintained. We recommend that you migrate your projects to pydrive2, the maintained fork of pydrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import shutil\n",
        "\n",
        "# folder_name = '/content/output'\n",
        "# shutil.make_archive(folder_name, 'zip', folder_name)\n",
        "# shutil.move('/content/output.zip', '/content/drive/MyDrive/ELL784/compressed_folder.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "MmRec-_eFMI0",
        "outputId": "19467a99-ed7a-400b-c87e-d94179f98f36"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/output.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# shutil.move('/content/output.zip', '/content/drive/MyDrive/ELL784/compressed_folder.zip')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "jQocbtQDInpk",
        "outputId": "aa7bbd84-39ec-40b8-8237-1d2d55c2de02"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/ELL784/compressed_folder.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # # import numpy as np\n",
        "# import cv2\n",
        "# import os\n",
        "# from datetime import datetime\n",
        "# from sklearn.cluster import KMeans\n",
        "\n",
        "# class GaussianMixture:\n",
        "#     def __init__(self, n_components=3, learning_rate=0.01, threshold=0.7):\n",
        "#         self.n_components = n_components\n",
        "#         self.learning_rate = learning_rate\n",
        "#         self.threshold = threshold\n",
        "#         self.weights = None\n",
        "#         self.means = None\n",
        "#         self.covars = None\n",
        "#         self.n_init = False\n",
        "\n",
        "#     def initialize(self, first_frame):\n",
        "#         height, width = first_frame.shape[:2]\n",
        "#         self.weights = np.ones((height, width, self.n_components)) / self.n_components\n",
        "#         self.means = np.zeros((height, width, self.n_components))\n",
        "#         self.covars = np.ones((height, width, self.n_components)) * 30\n",
        "\n",
        "#         # Initialize first Gaussian with first frame\n",
        "#         self.means[:,:,0] = first_frame\n",
        "#         self.n_init = True\n",
        "\n",
        "#     def gaussian_prob(self, x, mean, covar):\n",
        "#         diff = x - mean\n",
        "#         return np.exp(-diff * diff / (2 * covar)) / np.sqrt(2 * np.pi * covar)\n",
        "\n",
        "#     def update(self, frame):\n",
        "#         if not self.n_init:\n",
        "#             self.initialize(frame)\n",
        "#             return np.ones_like(frame, dtype=bool)\n",
        "\n",
        "#         height, width = frame.shape[:2]\n",
        "#         matches = np.zeros((height, width, self.n_components), dtype=bool)\n",
        "\n",
        "#         # Calculate match for each component\n",
        "#         for i in range(self.n_components):\n",
        "#             diff = np.abs(frame - self.means[:,:,i])\n",
        "#             matches[:,:,i] = diff < 2.5 * np.sqrt(self.covars[:,:,i])\n",
        "\n",
        "#         # Update parameters for matched components\n",
        "#         for i in range(self.n_components):\n",
        "#             match_pixels = matches[:,:,i]\n",
        "\n",
        "#             if np.any(match_pixels):\n",
        "#                 # Update weights\n",
        "#                 self.weights[:,:,i] = (1 - self.learning_rate) * self.weights[:,:,i]\n",
        "#                 self.weights[match_pixels,i] += self.learning_rate\n",
        "\n",
        "#                 # Update means and variances for matched pixels\n",
        "#                 pixel_diff = frame[match_pixels] - self.means[match_pixels,i]\n",
        "#                 self.means[match_pixels,i] += self.learning_rate * pixel_diff\n",
        "#                 self.covars[match_pixels,i] += self.learning_rate * (\n",
        "#                     pixel_diff * pixel_diff - self.covars[match_pixels,i]\n",
        "#                 )\n",
        "\n",
        "#         # Normalize weights\n",
        "#         weight_sum = np.sum(self.weights, axis=2)\n",
        "#         np.divide(self.weights, weight_sum[:,:,np.newaxis], out=self.weights)\n",
        "\n",
        "#         # Determine foreground pixels\n",
        "#         sorted_indices = np.argsort(self.weights, axis=2)\n",
        "#         sorted_weights = np.take_along_axis(self.weights, sorted_indices, axis=2)\n",
        "#         cumsum = np.cumsum(sorted_weights, axis=2)\n",
        "#         threshold_mask = cumsum < self.threshold\n",
        "\n",
        "#         background_prob = np.zeros((height, width))\n",
        "#         for i in range(self.n_components):\n",
        "#             background_prob += self.weights[:,:,i] * self.gaussian_prob(\n",
        "#                 frame, self.means[:,:,i], self.covars[:,:,i]\n",
        "#             )\n",
        "\n",
        "#         return background_prob < 0.1\n",
        "\n",
        "# class BackgroundSubtractor:\n",
        "#     def __init__(self, video_path, output_dir=\"output\"):\n",
        "#         self.video_path = video_path\n",
        "#         self.output_dir = output_dir\n",
        "#         self.gmm = GaussianMixture()\n",
        "#         self.setup_output_directories()\n",
        "\n",
        "#     def setup_output_directories(self):\n",
        "#         if not os.path.exists(self.output_dir):\n",
        "#             os.makedirs(self.output_dir)\n",
        "\n",
        "#         timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "#         self.frames_dir = os.path.join(self.output_dir, f\"frames_{timestamp}\")\n",
        "#         self.bg_dir = os.path.join(self.output_dir, f\"background_{timestamp}\")\n",
        "#         self.fg_dir = os.path.join(self.output_dir, f\"foreground_{timestamp}\")\n",
        "\n",
        "#         for directory in [self.frames_dir, self.bg_dir, self.fg_dir]:\n",
        "#             if not os.path.exists(directory):\n",
        "#                 os.makedirs(directory)\n",
        "\n",
        "#     def process_video(self):\n",
        "#         cap = cv2.VideoCapture(self.video_path)\n",
        "#         if not cap.isOpened():\n",
        "#             raise ValueError(\"Error opening video file\")\n",
        "\n",
        "#         frame_count = 0\n",
        "\n",
        "#         while True:\n",
        "#             ret, frame = cap.read()\n",
        "#             if not ret:\n",
        "#                 break\n",
        "\n",
        "#             # Convert to grayscale\n",
        "#             gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "#             # Get foreground mask using GMM\n",
        "#             foreground_mask_gmm = self.gmm.update(gray)\n",
        "\n",
        "#             # Refine foreground mask using K-Means\n",
        "#             foreground_mask_kmeans = self.refine_foreground_mask(frame, foreground_mask_gmm)\n",
        "\n",
        "#             # Save frames\n",
        "#             cv2.imwrite(f\"{self.frames_dir}/frame_{frame_count:04d}.jpg\", frame)\n",
        "\n",
        "#             # Create and save background/foreground\n",
        "#             background = frame.copy()\n",
        "#             foreground = frame.copy()\n",
        "\n",
        "#             background[foreground_mask_kmeans] = 0\n",
        "#             foreground[~foreground_mask_kmeans] = 0\n",
        "\n",
        "#             cv2.imwrite(f\"{self.bg_dir}/bg_{frame_count:04d}.jpg\", background)\n",
        "#             cv2.imwrite(f\"{self.fg_dir}/fg_{frame_count:04d}.jpg\", foreground)\n",
        "\n",
        "#             frame_count += 1\n",
        "\n",
        "#         cap.release()\n",
        "#         self.create_videos()\n",
        "#         self.save_parameters()\n",
        "\n",
        "#     def refine_foreground_mask(self, frame, foreground_mask_gmm):\n",
        "#         # Apply K-Means clustering to refine the foreground mask\n",
        "#         foreground_pixels = frame[foreground_mask_gmm]\n",
        "#         if len(foreground_pixels) == 0:\n",
        "#             return foreground_mask_gmm\n",
        "\n",
        "#         kmeans = KMeans(n_clusters=2)\n",
        "#         labels = kmeans.fit_predict(foreground_pixels.reshape(-1, 3))\n",
        "\n",
        "#         # Determine which cluster corresponds to the foreground\n",
        "#         cluster_centers = kmeans.cluster_centers_\n",
        "#         foreground_cluster = np.argmax(np.linalg.norm(cluster_centers - np.mean(frame, axis=(0, 1)), axis=1))\n",
        "\n",
        "#         # Create refined foreground mask\n",
        "#         refined_mask = np.zeros_like(foreground_mask_gmm, dtype=bool)\n",
        "#         refined_mask[foreground_mask_gmm] = labels == foreground_cluster\n",
        "\n",
        "#         return refined_mask\n",
        "\n",
        "#     def create_videos(self):\n",
        "#         def images_to_video(image_folder, output_path, fps=30):\n",
        "#             images = [img for img in os.listdir(image_folder) if img.endswith(\".jpg\")]\n",
        "#             images.sort()\n",
        "\n",
        "#             if not images:\n",
        "#                 return\n",
        "\n",
        "#             frame = cv2.imread(os.path.join(image_folder, images[0]))\n",
        "#             height, width = frame.shape[:2]\n",
        "\n",
        "#             fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "#             out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "#             for image in images:\n",
        "#                 frame = cv2.imread(os.path.join(image_folder, image))\n",
        "#                 out.write(frame)\n",
        "\n",
        "#             out.release()\n",
        "\n",
        "#         images_to_video(self.bg_dir, os.path.join(self.output_dir, \"background.mp4\"))\n",
        "#         images_to_video(self.fg_dir, os.path.join(self.output_dir, \"foreground.mp4\"))\n",
        "\n",
        "#     def save_parameters(self):\n",
        "#         params = f\"\"\"Background Subtraction Parameters\n",
        "# ========================\n",
        "# Timestamp: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}\n",
        "\n",
        "# GMM Parameters:\n",
        "# -------------\n",
        "# Number of components: {self.gmm.n_components}\n",
        "# Learning rate: {self.gmm.learning_rate}\n",
        "# Background threshold: {self.gmm.threshold}\n",
        "\n",
        "# Processing Details:\n",
        "# -----------------\n",
        "# Input video: {self.video_path}\n",
        "# Output directory: {self.output_dir}\n",
        "\n",
        "# Additional Information:\n",
        "# --------------------\n",
        "# - Implementation uses Gaussian Mixture Model (GMM) from scratch\n",
        "# - Foreground refinement uses K-Means clustering\n",
        "# - Background is modeled using {self.gmm.n_components} Gaussian components\n",
        "# - Pixels are classified as foreground when their probability is below threshold\n",
        "# - Sequential frame processing with online parameter updates\n",
        "# \"\"\"\n",
        "\n",
        "#         with open(os.path.join(self.output_dir, \"parameters.txt\"), \"w\") as f:\n",
        "#             f.write(params)\n",
        "\n",
        "# # Run the code\n",
        "# video_path = \"/content/video.mp4\"  # Replace with your video path\n",
        "# subtractor = BackgroundSubtractor(video_path)\n",
        "# subtractor.process_video()"
      ],
      "metadata": {
        "id": "CB5UCQ9F0H1a"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import shutil\n",
        "\n",
        "# folder_name = '/content/output'\n",
        "# shutil.make_archive(folder_name, 'zip', folder_name)\n",
        "# shutil.move('/content/output.zip', '/content/drive/MyDrive/ELL784/compressed_folder.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QEob7nNKKAPm",
        "outputId": "c4380430-dc9b-4c2d-9b3b-333eef391e5e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/output.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part3**"
      ],
      "metadata": {
        "id": "dnXNpMFl3KKJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "from datetime import datetime\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "class GaussianMixture:\n",
        "    def __init__(self, n_components=5, learning_rate=0.05, threshold=0.8):\n",
        "        self.n_components = n_components\n",
        "        self.learning_rate = learning_rate\n",
        "        self.threshold = threshold\n",
        "        self.weights = None\n",
        "        self.means = None\n",
        "        self.covars = None\n",
        "        self.n_init = False\n",
        "\n",
        "    def initialize(self, first_frame):\n",
        "        height, width = first_frame.shape[:2]\n",
        "        self.weights = np.ones((height, width, self.n_components)) / self.n_components\n",
        "        self.means = np.zeros((height, width, self.n_components))\n",
        "        self.covars = np.ones((height, width, self.n_components)) * 30\n",
        "\n",
        "        # Initialize first Gaussian with first frame\n",
        "        self.means[:,:,0] = first_frame\n",
        "        self.n_init = True\n",
        "\n",
        "    def gaussian_prob(self, x, mean, covar):\n",
        "        diff = x - mean\n",
        "        return np.exp(-diff * diff / (2 * covar)) / np.sqrt(2 * np.pi * covar)\n",
        "\n",
        "    def update(self, frame):\n",
        "        if not self.n_init:\n",
        "            self.initialize(frame)\n",
        "            return np.ones_like(frame, dtype=bool)\n",
        "\n",
        "        height, width = frame.shape[:2]\n",
        "        matches = np.zeros((height, width, self.n_components), dtype=bool)\n",
        "\n",
        "        # Calculate match for each component\n",
        "        for i in range(self.n_components):\n",
        "            diff = np.abs(frame - self.means[:,:,i])\n",
        "            matches[:,:,i] = diff < 2.0 * np.sqrt(self.covars[:,:,i])\n",
        "\n",
        "        # Update parameters for matched components\n",
        "        for i in range(self.n_components):\n",
        "            match_pixels = matches[:,:,i]\n",
        "\n",
        "            if np.any(match_pixels):\n",
        "                # Update weights\n",
        "                self.weights[:,:,i] = (1 - self.learning_rate) * self.weights[:,:,i]\n",
        "                self.weights[match_pixels,i] += self.learning_rate\n",
        "\n",
        "                # Update means and variances for matched pixels\n",
        "                pixel_diff = frame[match_pixels] - self.means[match_pixels,i]\n",
        "                self.means[match_pixels,i] += self.learning_rate * pixel_diff\n",
        "                self.covars[match_pixels,i] += self.learning_rate * (\n",
        "                    pixel_diff * pixel_diff - self.covars[match_pixels,i]\n",
        "                )\n",
        "\n",
        "        # Normalize weights\n",
        "        weight_sum = np.sum(self.weights, axis=2)\n",
        "        np.divide(self.weights, weight_sum[:,:,np.newaxis], out=self.weights)\n",
        "\n",
        "        # Determine foreground pixels\n",
        "        sorted_indices = np.argsort(self.weights, axis=2)\n",
        "        sorted_weights = np.take_along_axis(self.weights, sorted_indices, axis=2)\n",
        "        cumsum = np.cumsum(sorted_weights, axis=2)\n",
        "        threshold_mask = cumsum < self.threshold\n",
        "\n",
        "        background_prob = np.zeros((height, width))\n",
        "        for i in range(self.n_components):\n",
        "            background_prob += self.weights[:,:,i] * self.gaussian_prob(\n",
        "                frame, self.means[:,:,i], self.covars[:,:,i]\n",
        "            )\n",
        "\n",
        "        return background_prob < 0.15\n",
        "\n",
        "class BackgroundSubtractorSum:\n",
        "    def __init__(self, video_path, output_dir=\"output\"):\n",
        "        self.video_path = video_path\n",
        "        self.output_dir = output_dir\n",
        "        self.gmm = GaussianMixture()\n",
        "        self.setup_output_directories()\n",
        "\n",
        "    def setup_output_directories(self):\n",
        "        if not os.path.exists(self.output_dir):\n",
        "            os.makedirs(self.output_dir)\n",
        "\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        self.frames_dir = os.path.join(self.output_dir, f\"frames_{timestamp}\")\n",
        "        self.bg_dir = os.path.join(self.output_dir, f\"background_{timestamp}\")\n",
        "        self.fg_dir = os.path.join(self.output_dir, f\"foreground_{timestamp}\")\n",
        "\n",
        "        for directory in [self.frames_dir, self.bg_dir, self.fg_dir]:\n",
        "            if not os.path.exists(directory):\n",
        "                os.makedirs(directory)\n",
        "\n",
        "    def final_video_processor(self):\n",
        "        cap = cv2.VideoCapture(self.video_path)\n",
        "        if not cap.isOpened():\n",
        "            raise ValueError(\"Error opening video file\")\n",
        "\n",
        "        frame_count = 0\n",
        "\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            # Convert to grayscale\n",
        "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "            # Get foreground mask using GMM\n",
        "            foreground_mask_gmm = self.gmm.update(gray)\n",
        "\n",
        "            # Refine foreground mask using K-Means\n",
        "            foreground_mask_kmeans = self.refine_foreground_mask(frame, foreground_mask_gmm)\n",
        "\n",
        "            # Save frames\n",
        "            cv2.imwrite(f\"{self.frames_dir}/frame_{frame_count:04d}.jpg\", frame)\n",
        "\n",
        "            # Create and save background/foreground\n",
        "            background = frame.copy()\n",
        "            foreground = frame.copy()\n",
        "\n",
        "            background[foreground_mask_kmeans] = 0\n",
        "            foreground[~foreground_mask_kmeans] = 0\n",
        "\n",
        "            cv2.imwrite(f\"{self.bg_dir}/bg_{frame_count:04d}.jpg\", background)\n",
        "            cv2.imwrite(f\"{self.fg_dir}/fg_{frame_count:04d}.jpg\", foreground)\n",
        "\n",
        "            frame_count += 1\n",
        "\n",
        "        cap.release()\n",
        "        self.generate_videos()\n",
        "        self.save_parameters()\n",
        "\n",
        "    def refine_foreground_mask(self, frame, foreground_mask_gmm):\n",
        "        # Apply K-Means clustering to refine the foreground mask\n",
        "        foreground_pixels = frame[foreground_mask_gmm]\n",
        "        if len(foreground_pixels) == 0:\n",
        "            return foreground_mask_gmm\n",
        "\n",
        "        kmeans = KMeans(n_clusters=2)\n",
        "        labels = kmeans.fit_predict(foreground_pixels.reshape(-1, 3))\n",
        "\n",
        "        # Determine which cluster corresponds to the foreground\n",
        "        cluster_centers = kmeans.cluster_centers_\n",
        "        foreground_cluster = np.argmax(np.linalg.norm(cluster_centers - np.mean(frame, axis=(0, 1)), axis=1))\n",
        "\n",
        "        # Create refined foreground mask\n",
        "        refined_mask = np.zeros_like(foreground_mask_gmm, dtype=bool)\n",
        "        refined_mask[foreground_mask_gmm] = labels == foreground_cluster\n",
        "\n",
        "        return refined_mask\n",
        "\n",
        "    def generate_videos(self):\n",
        "        def images_to_video(image_folder, output_path, fps=30):\n",
        "            images = [img for img in os.listdir(image_folder) if img.endswith(\".jpg\")]\n",
        "            images.sort()\n",
        "\n",
        "            if not images:\n",
        "                return\n",
        "\n",
        "            frame = cv2.imread(os.path.join(image_folder, images[0]))\n",
        "            height, width = frame.shape[:2]\n",
        "\n",
        "            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "            out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "            for image in images:\n",
        "                frame = cv2.imread(os.path.join(image_folder, image))\n",
        "                out.write(frame)\n",
        "\n",
        "            out.release()\n",
        "\n",
        "        images_to_video(self.bg_dir, os.path.join(self.output_dir, \"background.mp4\"))\n",
        "        images_to_video(self.fg_dir, os.path.join(self.output_dir, \"foreground.mp4\"))\n",
        "\n",
        "    def save_parameters(self):\n",
        "        params = f\"\"\"Background Subtraction Parameters\n",
        "========================\n",
        "Timestamp: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}\n",
        "\n",
        "GMM Parameters:\n",
        "-------------\n",
        "Number of components: {self.gmm.n_components}\n",
        "Learning rate: {self.gmm.learning_rate}\n",
        "Background threshold: {self.gmm.threshold}\n",
        "\n",
        "Processing Details:\n",
        "-----------------\n",
        "Input video: {self.video_path}\n",
        "Output directory: {self.output_dir}\n",
        "\n",
        "Additional Information:\n",
        "--------------------\n",
        "- Implementation uses Gaussian Mixture Model (GMM) from scratch\n",
        "- Foreground refinement uses K-Means clustering\n",
        "- Background is modeled using {self.gmm.n_components} Gaussian components\n",
        "- Pixels are classified as foreground when their probability is below threshold\n",
        "- Sequential frame processing with online parameter updates\n",
        "\"\"\"\n",
        "\n",
        "        with open(os.path.join(self.output_dir, \"parameters.txt\"), \"w\") as f:\n",
        "            f.write(params)\n",
        "\n"
      ],
      "metadata": {
        "id": "BpH0CD_G1jB7"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "video_path = \"/content/summarized_video.mp4\"\n",
        "subtractor2 = BackgroundSubtractorSum(video_path)\n",
        "subtractor2.final_video_processor()"
      ],
      "metadata": {
        "id": "QpvPQr3g2Z8F"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "folder_name = '/content/output'\n",
        "shutil.make_archive(folder_name, 'zip', folder_name)\n"
      ],
      "metadata": {
        "id": "gnLSf1kH3x-Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "eb55d2d1-029c-454c-8d2f-37d84e2b071b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/output.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.move('/content/output_sum.zip', '/content/drive/MyDrive/ELL784/output_sum_compress.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ORdHgBs8Pydk",
        "outputId": "def2664c-c342-453a-f361-295a071dc629"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/ELL784/output_sum_compress.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sxyyb1b0QAwl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}